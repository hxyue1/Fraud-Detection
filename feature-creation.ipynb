{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'm going to experiment with feature creation with the numeric variables in our data set using a few techniques. I will select the important ones using permutation importance. The techniques I'm going to try out are:\n",
    "\n",
    "\n",
    "- means for particular categories\n",
    "- standard deviations for particular categories\n",
    "- standardised deviations from the uncoditional mean (and maybe the conditional mean for a particular category)\n",
    "- frequency counts for different categories\n",
    "- interaction terms via cross products\n",
    "\n",
    "At each stage, I'll evaluate each feature by running a logistic regression and scoring it using the roc_auc_score. Useful features should have values greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining feature evaluation function\n",
    "def feature_auc(X,y,test_size):\n",
    "    \n",
    "    #Concatenating to drop nas\n",
    "    temp = pd.concat([y,X],axis=1)\n",
    "    temp = temp.dropna()\n",
    "    y=temp.iloc[:,0:1]\n",
    "    X=temp.iloc[:,1:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size, shuffle=False) \n",
    "    model = LogisticRegression(solver='lbfgs').fit(X_train,np.array(y_train).ravel())\n",
    "    preds = model.predict_proba(X_test)\n",
    "    score = roc_auc_score(y_test,preds[:,1])\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function to deal with NAs by shuffling and forward filling.\n",
    "\n",
    "def ffill(df):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    na_count = df.isna().sum().sum()\n",
    "    while na_count>0:\n",
    "        df = df.sample(frac=1)\n",
    "        df = df.fillna(method='ffill',limit=10)\n",
    "        na_count = df.isna().sum().sum()\n",
    "\n",
    "    \n",
    "    df = df.sort_index()\n",
    "    t1 = time.time()\n",
    "\n",
    "    return(df)\n",
    "    print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('Data/train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = train_transaction['isFraud']\n",
    "train_transaction.drop('isFraud',axis=1,inplace=True)\n",
    "strings = train_transaction.select_dtypes(include='object')\n",
    "numerics = train_transaction.select_dtypes(exclude='object')\n",
    "\n",
    "del train_transaction\n",
    "\n",
    "numerics = ffill(numerics)\n",
    "strings = strings.fillna('NaN')\n",
    "\n",
    "train_transaction = pd.concat([fraud,numerics,strings],axis=1)\n",
    "\n",
    "del numerics, strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = train_transaction.iloc[:200000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first features we are going to create are card counts and average transaction amounts for each card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5115938349609495"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = use['isFraud']\n",
    "temp = use['card4'].value_counts().to_dict()\n",
    "use['card4_counts'] = use['card4'].map(temp)\n",
    "\n",
    "feature_auc(use['card4_counts'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5091185459658263"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_means = use.groupby('card4')['TransactionAmt'].agg(['mean']).to_dict()\n",
    "use['card4_mean_spend'] = use['card4'].map(card_means['mean'])\n",
    "feature_auc(use['card4_mean_spend'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to create a variable which calculates the deviation from the mean for a particular transaction. The means will be conditional on the card type e.g. Visa, Mastercard etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5100160501571082"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use['card4_spend_dev'] = use['TransactionAmt'] - use['card4_mean_spend']\n",
    "feature_auc(use['card4_spend_dev'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if standardisation makes a difference, I will be dividing by the standard deviation of the transaction amounts. That standard deviation will be taken over the transactions for a particular card types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5098732026849845"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_stds = use.groupby('card4')['TransactionAmt'].agg(['std']).to_dict()\n",
    "use['card4_spend_dev_std'] = use['card4_spend_dev']/use['card4'].map(card_stds['std'])\n",
    "feature_auc(use['card4_spend_dev_std'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem to make much of a difference. How about the standard deviations themselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5128556847091534"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use['card4_spend_std'] = use['card4'].map(card_stds['std'])\n",
    "feature_auc(use['card4_spend_std'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks somewhat promising. Note, these are just point estimates so we have no idea if it is actually statistically significant. These values could be positive just due to random chance. However this is probably not the case since we used a large number of observations to calculate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've got five techniques to aggregate continous data across different categories and a way to evaluate their usefulness. One way would be to exhaustively evaluate all possible combinations, but with my limited computational budget, I don't think that's practical. While I'm not very good at this, I'll have to think about the problem in more depth to come up with potentially useful combinations.\n",
    "\n",
    "In the mean time let's create a function that allows us to evaluate categorical numerical pairs using the five above techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_aggregation_eval(categorical, numerical, df):\n",
    "    \n",
    "    counts_temp = df[categorical].value_counts().to_dict()\n",
    "    counts = df[categorical].map(counts_temp)\n",
    "    counts_auc = feature_auc(counts,fraud,0.5)\n",
    "    \n",
    "    means_temp = df.groupby(categorical)[numerical].agg(['mean']).to_dict()\n",
    "    means = df[categorical].map(means_temp['mean'])\n",
    "    means_auc = feature_auc(means,fraud,0.5)\n",
    "    \n",
    "    stds_temp = df.groupby(categorical)[numerical].agg(['std']).to_dict()\n",
    "    stds = df[categorical].map(stds_temp['std'])\n",
    "    stds_auc = feature_auc(stds,fraud,0.5)\n",
    "    \n",
    "    devs = df[numerical] - means\n",
    "    devs_auc = feature_auc(devs,fraud,0.5)\n",
    "    \n",
    "    std_devs = devs/stds\n",
    "    std_devs_auc = feature_auc(std_devs,fraud,0.5)\n",
    "    \n",
    "    scores = {\n",
    "        'feature_type':['counts', 'means', 'stds', 'devs', 'std_devs'],\n",
    "        'auc':[counts_auc, means_auc, stds_auc, devs_auc, std_devs_auc]\n",
    "    }\n",
    "    \n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "card4_transamt = feature_aggregation_eval(categorical='card4', numerical='TransactionAmt', df=use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to ramp things up a bit so that the feature evaluation function will loop through all possible combinations of selected numeric and categorical variables. That way we can identify good features more exhaustively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_aggregation_eval_2(categorical_variables, numerical_variables, df):\n",
    "    \n",
    "    combination_scores = {}\n",
    "    \n",
    "    for numerical in numerical_variables:\n",
    "        for categorical in categorical_variables:\n",
    " \n",
    "        \n",
    "            counts_temp = df[categorical].value_counts().to_dict()\n",
    "            counts = df[categorical].map(counts_temp)\n",
    "            counts_auc = feature_auc(counts,fraud,0.5)\n",
    "\n",
    "            means_temp = df.groupby(categorical)[numerical].agg(['mean']).to_dict()\n",
    "            means = df[categorical].map(means_temp['mean'])\n",
    "            means_auc = feature_auc(means,fraud,0.5)\n",
    "\n",
    "            stds_temp = df.groupby(categorical)[numerical].agg(['std']).to_dict()\n",
    "            stds = df[categorical].map(stds_temp['std'])\n",
    "            stds_auc = feature_auc(stds,fraud,0.5)\n",
    "\n",
    "            devs = df[numerical] - means\n",
    "            devs_auc = feature_auc(devs,fraud,0.5)\n",
    "\n",
    "            std_devs = devs/stds\n",
    "            std_devs_auc = feature_auc(std_devs,fraud,0.5)\n",
    "\n",
    "            scores = {\n",
    "                'feature_type':['counts', 'means', 'stds', 'devs', 'std_devs'],\n",
    "                'auc':[counts_auc, means_auc, stds_auc, devs_auc, std_devs_auc]\n",
    "            }           \n",
    "    \n",
    "            scores = pd.DataFrame.from_dict(scores)\n",
    "        \n",
    "            name = categorical + '.'  + numerical\n",
    "            combination_scores[name] = scores\n",
    "            \n",
    "    return(combination_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD.TransactionDT\n",
      "  feature_type       auc\n",
      "0       counts  0.635902\n",
      "1        means  0.638352\n",
      "2         stds  0.637701\n",
      "3         devs  0.593297\n",
      "4     std_devs  0.384229\n"
     ]
    }
   ],
   "source": [
    "scores = feature_aggregation_eval_2(\n",
    "    categorical_variables = ['ProductCD'],\n",
    "    numerical_variables = ['TransactionDT'],\n",
    "    df = use)\n",
    "\n",
    "for key in scores.keys():\n",
    "    print(key)\n",
    "    print(scores[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations_filter(dict_of_dfs, lower_bound):\n",
    "    scores = dict_of_dfs\n",
    "    combinations = []\n",
    "    for key in scores.keys():\n",
    "\n",
    "        names = key.split('.')\n",
    "        categorical = names[0]\n",
    "        numerical = names[1]\n",
    "\n",
    "        for i in np.arange(0,5):\n",
    "            if scores[key]['auc'].iloc[i] > lower_bound:\n",
    "                method = scores[key]['feature_type'].iloc[i]\n",
    "                combination = [categorical, numerical, method]\n",
    "                combinations.append(combination)\n",
    "\n",
    "    return(combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good idea of what features might be worth creating, I'm going to create a function that appends these new features to our dataframe of explanatory variables. The function will take a tuple and dataframe as input. The tuple contains the numerical variable to be aggregated, the categorical variable to be aggregated across, and the aggregation method. \n",
    "\n",
    "I will do this acros two functions, one that creates the feature itself, and an outer loop that appends each categorical-numerical-method tuple to the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_creation(categorical, numerical, method, df):\n",
    "    \n",
    "    #Creating some features by default because they will probably be needed anyway\n",
    "    means_temp = df.groupby(categorical)[numerical].agg(['mean']).to_dict()\n",
    "    means = df[categorical].map(means_temp['mean'])\n",
    "    \n",
    "    stds_temp = df.groupby(categorical)[numerical].agg(['std']).to_dict()\n",
    "    stds = df[categorical].map(stds_temp['std'])\n",
    "    \n",
    "    \n",
    "    if method == 'counts':\n",
    "        counts_temp = df[categorical].value_counts().to_dict()\n",
    "        counts = df[categorical].map(counts_temp)\n",
    "        return(counts)\n",
    "    \n",
    "    if method == 'means':\n",
    "        return(means)\n",
    "    \n",
    "    if method == 'stds':\n",
    "        return(stds)\n",
    "    \n",
    "    if method == \"devs\":\n",
    "        devs = df[numerical] - means\n",
    "        return(devs)\n",
    "    \n",
    "    if method == \"std_devs\":\n",
    "        devs = df[numerical] - means\n",
    "        std_devs = devs/stds\n",
    "        return(std_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_aggregation_creation(combination_list, df):\n",
    "    out_df = pd.DataFrame(\n",
    "        {'temp':np.zeros(len(df))}\n",
    "    )\n",
    "    \n",
    "    for i in np.arange(0,len(combination_list)):\n",
    "        combination = combination_list[i]\n",
    "        \n",
    "        print(combination)\n",
    "        feature = feature_creation(\n",
    "            categorical = combination[0],\n",
    "            numerical = combination[1],\n",
    "            method = combination[2],\n",
    "            df=df)\n",
    "        \n",
    "        name = combination[0] + '.' + combination[1] + '.' + combination[2]\n",
    "        out_df[name] = feature\n",
    "        \n",
    "    out_df.drop('temp',axis=1,inplace=True)\n",
    "    return(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_rankings = pd.read_csv('Data/numerics_rankings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_numeric_features = numerics_rankings.iloc[:20]['feature'].tolist()\n",
    "strong_categorical_features = ['M5','P_emaildomain','M4','ProductCD','card6','M6','R_emaildomain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = feature_aggregation_eval_2(\n",
    "    categorical_variables = strong_categorical_features,\n",
    "    numerical_variables = strong_numeric_features,\n",
    "    df = use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = combinations_filter(scores,0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M4', 'V255', 'means']\n",
      "['M4', 'V255', 'stds']\n",
      "['M4', 'V67', 'stds']\n",
      "['ProductCD', 'V67', 'means']\n",
      "['ProductCD', 'V67', 'stds']\n",
      "['M6', 'V67', 'stds']\n",
      "['R_emaildomain', 'V67', 'means']\n",
      "['R_emaildomain', 'V67', 'stds']\n",
      "['R_emaildomain', 'V289', 'means']\n",
      "['R_emaildomain', 'V289', 'devs']\n",
      "['ProductCD', 'V39', 'means']\n",
      "['ProductCD', 'V39', 'stds']\n",
      "['M6', 'V39', 'means']\n",
      "['R_emaildomain', 'V39', 'means']\n",
      "['R_emaildomain', 'V39', 'stds']\n",
      "['M6', 'V115', 'means']\n",
      "['M6', 'V115', 'stds']\n",
      "['M6', 'V115', 'devs']\n",
      "['M6', 'V115', 'std_devs']\n",
      "['M4', 'V319', 'means']\n",
      "['M4', 'V319', 'devs']\n",
      "['R_emaildomain', 'V319', 'stds']\n",
      "['M6', 'TransactionID', 'means']\n",
      "['M4', 'V62', 'means']\n",
      "['ProductCD', 'V62', 'means']\n",
      "['ProductCD', 'V62', 'stds']\n",
      "['M6', 'V62', 'means']\n",
      "['R_emaildomain', 'V62', 'means']\n",
      "['R_emaildomain', 'V62', 'stds']\n",
      "['M4', 'V82', 'means']\n",
      "['ProductCD', 'V82', 'means']\n",
      "['ProductCD', 'V82', 'stds']\n",
      "['R_emaildomain', 'V82', 'means']\n",
      "['R_emaildomain', 'V82', 'stds']\n",
      "['M4', 'V283', 'means']\n",
      "['ProductCD', 'V283', 'means']\n",
      "['M6', 'V283', 'means']\n",
      "['M6', 'V283', 'stds']\n",
      "['R_emaildomain', 'V283', 'means']\n",
      "['ProductCD', 'C5', 'means']\n",
      "['ProductCD', 'C5', 'stds']\n",
      "['M6', 'C5', 'means']\n",
      "['M6', 'C5', 'stds']\n",
      "['R_emaildomain', 'C5', 'means']\n",
      "['R_emaildomain', 'C5', 'stds']\n",
      "['M4', 'V308', 'std_devs']\n",
      "['ProductCD', 'V308', 'devs']\n",
      "['ProductCD', 'V308', 'std_devs']\n",
      "['card6', 'V308', 'std_devs']\n",
      "['M6', 'V308', 'means']\n",
      "['M6', 'V308', 'devs']\n",
      "['M6', 'V308', 'std_devs']\n",
      "['R_emaildomain', 'V308', 'means']\n",
      "['R_emaildomain', 'V308', 'devs']\n",
      "['R_emaildomain', 'V308', 'std_devs']\n",
      "['M4', 'TransactionAmt', 'means']\n",
      "['M4', 'TransactionAmt', 'stds']\n",
      "['ProductCD', 'TransactionAmt', 'stds']\n",
      "['ProductCD', 'TransactionAmt', 'devs']\n",
      "['M6', 'TransactionAmt', 'means']\n",
      "['M6', 'TransactionAmt', 'stds']\n",
      "['R_emaildomain', 'TransactionAmt', 'means']\n",
      "['R_emaildomain', 'TransactionAmt', 'stds']\n",
      "['M4', 'V281', 'means']\n",
      "['M4', 'V281', 'stds']\n",
      "['M6', 'V281', 'means']\n",
      "['M6', 'V281', 'stds']\n",
      "['R_emaildomain', 'V281', 'means']\n",
      "['M4', 'C14', 'stds']\n",
      "['R_emaildomain', 'C14', 'means']\n",
      "['R_emaildomain', 'C14', 'stds']\n",
      "['M4', 'V313', 'stds']\n",
      "['ProductCD', 'V313', 'means']\n",
      "['ProductCD', 'V313', 'stds']\n",
      "['ProductCD', 'V313', 'devs']\n",
      "['M6', 'V313', 'means']\n",
      "['M6', 'V313', 'stds']\n",
      "['M6', 'V313', 'devs']\n",
      "['R_emaildomain', 'V313', 'means']\n",
      "['R_emaildomain', 'V313', 'stds']\n",
      "['R_emaildomain', 'V313', 'devs']\n",
      "['P_emaildomain', 'V317', 'std_devs']\n",
      "['M4', 'V317', 'std_devs']\n",
      "['ProductCD', 'V317', 'std_devs']\n",
      "['card6', 'V317', 'std_devs']\n",
      "['M6', 'V317', 'means']\n",
      "['M6', 'V317', 'devs']\n",
      "['M6', 'V317', 'std_devs']\n",
      "['R_emaildomain', 'V317', 'devs']\n",
      "['R_emaildomain', 'V317', 'std_devs']\n",
      "['M4', 'C1', 'stds']\n",
      "['M6', 'C1', 'std_devs']\n",
      "['R_emaildomain', 'C1', 'means']\n",
      "['R_emaildomain', 'C1', 'stds']\n",
      "['M4', 'C11', 'stds']\n",
      "['M6', 'C11', 'std_devs']\n",
      "['R_emaildomain', 'C11', 'means']\n",
      "['R_emaildomain', 'C11', 'stds']\n"
     ]
    }
   ],
   "source": [
    "new_features = feature_aggregation_creation(combinations,use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_numerical_feats = use[strong_numeric_features]\n",
    "best_categorical_feats = use[strong_categorical_features]\n",
    "best_categorical_feats = best_categorical_feats.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = pd.concat([best_numerical_feats,best_categorical_feats,new_features],axis=1)\n",
    "\n",
    "hybrid = ffill(hybrid)\n",
    "\n",
    "hybrid_train = hybrid.iloc[:100000,:]\n",
    "hybrid_val = hybrid.iloc[100000:200000,:]\n",
    "\n",
    "fraud_train = fraud.iloc[:100000]\n",
    "fraud_val = fraud.iloc[100000:200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've added these new features and encoded the strings, let's give this new data a test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.808329\n",
      "Will train until validation_0-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.827736\n",
      "[2]\tvalidation_0-auc:0.827852\n",
      "[3]\tvalidation_0-auc:0.832467\n",
      "[4]\tvalidation_0-auc:0.834063\n",
      "[5]\tvalidation_0-auc:0.83866\n",
      "[6]\tvalidation_0-auc:0.839191\n",
      "[7]\tvalidation_0-auc:0.839093\n",
      "[8]\tvalidation_0-auc:0.830729\n",
      "[9]\tvalidation_0-auc:0.83583\n",
      "[10]\tvalidation_0-auc:0.834793\n",
      "[11]\tvalidation_0-auc:0.834699\n",
      "[12]\tvalidation_0-auc:0.827965\n",
      "[13]\tvalidation_0-auc:0.831599\n",
      "[14]\tvalidation_0-auc:0.832748\n",
      "[15]\tvalidation_0-auc:0.833632\n",
      "[16]\tvalidation_0-auc:0.833985\n",
      "Stopping. Best iteration:\n",
      "[6]\tvalidation_0-auc:0.839191\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.2,\n",
       "       max_delta_step=0, max_depth=10, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    learning_rate = 0.2,\n",
    "    n_estimators = 100,\n",
    "    max_depth = 10,\n",
    "    objective = 'binary:logistic'\n",
    ") \n",
    "\n",
    "model.fit(hybrid_train, fraud_train, \n",
    "          eval_metric = \"auc\", \n",
    "          eval_set= [(hybrid_val, fraud_val)],\n",
    "          early_stopping_rounds = 10\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've fitted our model, now let's check if the new variables actually contribute amything of significance as opposed to paraphrasing what already exists in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm_hybrid = PermutationImportance(model, random_state=1).fit(hybrid_val.iloc[:50000], fraud_val.iloc[:50000])\n",
    "perm_hybrid_df = eli5.explain_weights_df(perm_hybrid, feature_names = hybrid.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "      <th>standardised_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V62</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C14</td>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>40.922157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>V308</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>31.843367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M6.C1.std_devs</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>28.367899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V67</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>25.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>22.908548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C11</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>14.937941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V283</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>14.301870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ProductCD.V317.std_devs</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>11.191302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>card6</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>9.406045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M4.V317.std_devs</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>9.186382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M6.V317.std_devs</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M6.C11.std_devs</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>6.254021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M5</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>5.620856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>V281</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>5.612486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>V289</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>V39</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.307228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V255</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>5.078334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ProductCD.V313.devs</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>4.938815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>R_emaildomain.V308.means</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>4.290582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>M6.V313.devs</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>3.878359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_emaildomain.V67.stds</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>3.801464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>V313</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.741657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C5</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.601470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>R_emaildomain.V289.devs</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>3.535534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TransactionAmt</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>3.458989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R_emaildomain.V317.std_devs</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>3.433759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P_emaildomain</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2.506513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ProductCD.TransactionAmt.devs</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>2.285393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>R_emaildomain</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>2.059219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>M4.C14.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>R_emaildomain.C14.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>M4.V313.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ProductCD.V313.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>M6.V313.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>M6.V313.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>R_emaildomain.V313.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>M6.V317.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>M4.C1.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>R_emaildomain.C1.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>R_emaildomain.C1.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>M4.C11.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>M4.TransactionAmt.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>M6.TransactionAmt.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ProductCD.V283.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>R_emaildomain.V283.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M6.V308.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ProductCD.V82.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>R_emaildomain.V82.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>R_emaildomain.V82.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>R_emaildomain.C5.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>R_emaildomain.C5.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>M6.C5.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>M4.V283.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>M6.C5.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ProductCD.C5.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ProductCD.C5.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>R_emaildomain.C11.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>M6.V283.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>M6.V283.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature    weight       std  standardised_weight\n",
       "11                             V62  0.000380  0.000000                  inf\n",
       "0                              C14  0.009040  0.000221            40.922157\n",
       "14                            V308  0.000312  0.000010            31.843367\n",
       "1                   M6.C1.std_devs  0.005644  0.000199            28.367899\n",
       "9                              V67  0.000408  0.000016            25.500000\n",
       "2                               C1  0.002300  0.000100            22.908548\n",
       "4                              C11  0.001632  0.000109            14.937941\n",
       "5                             V283  0.000776  0.000054            14.301870\n",
       "3          ProductCD.V317.std_devs  0.001776  0.000159            11.191302\n",
       "12                           card6  0.000328  0.000035             9.406045\n",
       "7                 M4.V317.std_devs  0.000456  0.000050             9.186382\n",
       "21                M6.V317.std_devs  0.000128  0.000016             8.000000\n",
       "8                  M6.C11.std_devs  0.000408  0.000065             6.254021\n",
       "6                               M5  0.000676  0.000120             5.620856\n",
       "25                            V281  0.000084  0.000015             5.612486\n",
       "31                            V289  0.000044  0.000008             5.500000\n",
       "20                             V39  0.000156  0.000029             5.307228\n",
       "15                            V255  0.000280  0.000055             5.078334\n",
       "10             ProductCD.V313.devs  0.000380  0.000077             4.938815\n",
       "19        R_emaildomain.V308.means  0.000180  0.000042             4.290582\n",
       "27                    M6.V313.devs  0.000076  0.000020             3.878359\n",
       "17          R_emaildomain.V67.stds  0.000248  0.000065             3.801464\n",
       "29                            V313  0.000056  0.000015             3.741657\n",
       "26                              C5  0.000084  0.000023             3.601470\n",
       "22         R_emaildomain.V289.devs  0.000100  0.000028             3.535534\n",
       "18                  TransactionAmt  0.000208  0.000060             3.458989\n",
       "13     R_emaildomain.V317.std_devs  0.000312  0.000091             3.433759\n",
       "28                   P_emaildomain  0.000068  0.000027             2.506513\n",
       "16   ProductCD.TransactionAmt.devs  0.000264  0.000116             2.285393\n",
       "24                   R_emaildomain  0.000084  0.000041             2.059219\n",
       "..                             ...       ...       ...                  ...\n",
       "80                     M4.C14.stds  0.000000  0.000000                  NaN\n",
       "81         R_emaildomain.C14.means  0.000000  0.000000                  NaN\n",
       "82                    M4.V313.stds  0.000000  0.000000                  NaN\n",
       "83             ProductCD.V313.stds  0.000000  0.000000                  NaN\n",
       "84                   M6.V313.means  0.000000  0.000000                  NaN\n",
       "85                    M6.V313.stds  0.000000  0.000000                  NaN\n",
       "86         R_emaildomain.V313.stds  0.000000  0.000000                  NaN\n",
       "87                   M6.V317.means  0.000000  0.000000                  NaN\n",
       "88                      M4.C1.stds  0.000000  0.000000                  NaN\n",
       "89          R_emaildomain.C1.means  0.000000  0.000000                  NaN\n",
       "90           R_emaildomain.C1.stds  0.000000  0.000000                  NaN\n",
       "91                     M4.C11.stds  0.000000  0.000000                  NaN\n",
       "92          M4.TransactionAmt.stds  0.000000  0.000000                  NaN\n",
       "93          M6.TransactionAmt.stds  0.000000  0.000000                  NaN\n",
       "94            ProductCD.V283.means  0.000000  0.000000                  NaN\n",
       "95        R_emaildomain.V283.means  0.000000  0.000000                  NaN\n",
       "96                   M6.V308.means  0.000000  0.000000                  NaN\n",
       "97              ProductCD.V82.stds  0.000000  0.000000                  NaN\n",
       "98         R_emaildomain.V82.means  0.000000  0.000000                  NaN\n",
       "99          R_emaildomain.V82.stds  0.000000  0.000000                  NaN\n",
       "100          R_emaildomain.C5.stds  0.000000  0.000000                  NaN\n",
       "101         R_emaildomain.C5.means  0.000000  0.000000                  NaN\n",
       "102                     M6.C5.stds  0.000000  0.000000                  NaN\n",
       "103                  M4.V283.means  0.000000  0.000000                  NaN\n",
       "104                    M6.C5.means  0.000000  0.000000                  NaN\n",
       "105              ProductCD.C5.stds  0.000000  0.000000                  NaN\n",
       "106             ProductCD.C5.means  0.000000  0.000000                  NaN\n",
       "107        R_emaildomain.C11.means  0.000000  0.000000                  NaN\n",
       "108                  M6.V283.means  0.000000  0.000000                  NaN\n",
       "109                   M6.V283.stds  0.000000  0.000000                  NaN\n",
       "\n",
       "[125 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_hybrid_df['standardised_weight'] = perm_hybrid_df['weight']/perm_hybrid_df['std']\n",
    "perm_hybrid_df = perm_hybrid_df.sort_values('standardised_weight',ascending=False)\n",
    "perm_hybrid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
