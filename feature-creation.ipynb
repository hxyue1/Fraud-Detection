{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'm going to experiment with feature creation with the numeric variables in our data set using a few techniques. I will select the important ones using permutation importance. The techniques I'm going to try out are:\n",
    "\n",
    "\n",
    "- means for particular categories\n",
    "- standard deviations for particular categories\n",
    "- standardised deviations from the uncoditional mean (and maybe the conditional mean for a particular category)\n",
    "- frequency counts for different categories\n",
    "- interaction terms via cross products\n",
    "\n",
    "At each stage, I'll evaluate each feature by running a logistic regression and scoring it using the roc_auc_score. Useful features should have values greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining feature evaluation function\n",
    "def feature_auc(X,y,test_size):\n",
    "    \n",
    "    #Concatenating to drop nas\n",
    "    temp = pd.concat([y,X],axis=1)\n",
    "    temp = temp.dropna()\n",
    "    y=temp.iloc[:,0:1]\n",
    "    X=temp.iloc[:,1:]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size, shuffle=False) \n",
    "    model = LogisticRegression(solver='lbfgs').fit(X_train,np.array(y_train).ravel())\n",
    "    preds = model.predict_proba(X_test)\n",
    "    score = roc_auc_score(y_test,preds[:,1])\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function to deal with NAs by shuffling and forward filling.\n",
    "\n",
    "def ffill(df):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    na_count = df.isna().sum().sum()\n",
    "    while na_count>0:\n",
    "        df = df.sample(frac=1)\n",
    "        df = df.fillna(method='ffill',limit=10)\n",
    "        na_count = df.isna().sum().sum()\n",
    "\n",
    "    \n",
    "    df = df.sort_index()\n",
    "    t1 = time.time()\n",
    "\n",
    "    return(df)\n",
    "    print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('Data/train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = train_transaction['isFraud']\n",
    "train_transaction.drop('isFraud',axis=1,inplace=True)\n",
    "strings = train_transaction.select_dtypes(include='object')\n",
    "numerics = train_transaction.select_dtypes(exclude='object')\n",
    "\n",
    "del train_transaction\n",
    "\n",
    "numerics = ffill(numerics)\n",
    "strings = strings.fillna('NaN')\n",
    "\n",
    "train_transaction = pd.concat([fraud,numerics,strings],axis=1)\n",
    "\n",
    "del numerics, strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = train_transaction.iloc[:200000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first features we are going to create are card counts and average transaction amounts for each card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5115938349609495"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = use['isFraud']\n",
    "temp = use['card4'].value_counts().to_dict()\n",
    "use['card4_counts'] = use['card4'].map(temp)\n",
    "\n",
    "feature_auc(use['card4_counts'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5091185459658263"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_means = use.groupby('card4')['TransactionAmt'].agg(['mean']).to_dict()\n",
    "use['card4_mean_spend'] = use['card4'].map(card_means['mean'])\n",
    "feature_auc(use['card4_mean_spend'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to create a variable which calculates the deviation from the mean for a particular transaction. The means will be conditional on the card type e.g. Visa, Mastercard etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5100160501571082"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use['card4_spend_dev'] = use['TransactionAmt'] - use['card4_mean_spend']\n",
    "feature_auc(use['card4_spend_dev'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if standardisation makes a difference, I will be dividing by the standard deviation of the transaction amounts. That standard deviation will be taken over the transactions for a particular card types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5098732026849845"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_stds = use.groupby('card4')['TransactionAmt'].agg(['std']).to_dict()\n",
    "use['card4_spend_dev_std'] = use['card4_spend_dev']/use['card4'].map(card_stds['std'])\n",
    "feature_auc(use['card4_spend_dev_std'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't seem to make much of a difference. How about the standard deviations themselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5128556847091534"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use['card4_spend_std'] = use['card4'].map(card_stds['std'])\n",
    "feature_auc(use['card4_spend_std'],fraud,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks somewhat promising. Note, these are just point estimates so we have no idea if it is actually statistically significant. These values could be positive just due to random chance. However this is probably not the case since we used a large number of observations to calculate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we've got five techniques to aggregate continous data across different categories and a way to evaluate their usefulness. One way would be to exhaustively evaluate all possible combinations, but with my limited computational budget, I don't think that's practical. While I'm not very good at this, I'll have to think about the problem in more depth to come up with potentially useful combinations.\n",
    "\n",
    "In the mean time let's create a function that allows us to evaluate categorical numerical pairs using the five above techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_aggregation_eval(categorical, numerical, df):\n",
    "    \n",
    "    counts_temp = df[categorical].value_counts().to_dict()\n",
    "    counts = df[categorical].map(counts_temp)\n",
    "    counts_auc = feature_auc(counts,fraud,0.5)\n",
    "    \n",
    "    means_temp = df.groupby(categorical)[numerical].agg(['mean']).to_dict()\n",
    "    means = df[categorical].map(means_temp['mean'])\n",
    "    means_auc = feature_auc(means,fraud,0.5)\n",
    "    \n",
    "    stds_temp = df.groupby(categorical)[numerical].agg(['std']).to_dict()\n",
    "    stds = df[categorical].map(stds_temp['std'])\n",
    "    stds_auc = feature_auc(stds,fraud,0.5)\n",
    "    \n",
    "    devs = df[numerical] - means\n",
    "    devs_auc = feature_auc(devs,fraud,0.5)\n",
    "    \n",
    "    std_devs = devs/stds\n",
    "    std_devs_auc = feature_auc(std_devs,fraud,0.5)\n",
    "    \n",
    "    scores = {\n",
    "        'feature_type':['counts', 'means', 'stds', 'devs', 'std_devs'],\n",
    "        'auc':[counts_auc, means_auc, stds_auc, devs_auc, std_devs_auc]\n",
    "    }\n",
    "    \n",
    "    scores = pd.DataFrame.from_dict(scores)\n",
    "    return(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "card4_transamt = feature_aggregation_eval(categorical='card4', numerical='TransactionAmt', df=use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to ramp things up a bit so that the feature evaluation function will loop through all possible combinations of selected numeric and categorical variables. That way we can identify good features more exhaustively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_aggregation_eval_2(categorical_variables, numerical_variables, df):\n",
    "    \n",
    "    combination_scores = {}\n",
    "    \n",
    "    for numerical in numerical_variables:\n",
    "        for categorical in categorical_variables:\n",
    " \n",
    "        \n",
    "            counts_temp = df[categorical].value_counts().to_dict()\n",
    "            counts = df[categorical].map(counts_temp)\n",
    "            counts_auc = feature_auc(counts,fraud,0.5)\n",
    "\n",
    "            means_temp = df.groupby(categorical)[numerical].agg(['mean']).to_dict()\n",
    "            means = df[categorical].map(means_temp['mean'])\n",
    "            means_auc = feature_auc(means,fraud,0.5)\n",
    "\n",
    "            stds_temp = df.groupby(categorical)[numerical].agg(['std']).to_dict()\n",
    "            stds = df[categorical].map(stds_temp['std'])\n",
    "            stds_auc = feature_auc(stds,fraud,0.5)\n",
    "\n",
    "            devs = df[numerical] - means\n",
    "            devs_auc = feature_auc(devs,fraud,0.5)\n",
    "\n",
    "            std_devs = devs/stds\n",
    "            std_devs_auc = feature_auc(std_devs,fraud,0.5)\n",
    "\n",
    "            scores = {\n",
    "                'feature_type':['counts', 'means', 'stds', 'devs', 'std_devs'],\n",
    "                'auc':[counts_auc, means_auc, stds_auc, devs_auc, std_devs_auc]\n",
    "            }           \n",
    "    \n",
    "            scores = pd.DataFrame.from_dict(scores)\n",
    "        \n",
    "            name = categorical + '.'  + numerical\n",
    "            combination_scores[name] = scores\n",
    "            \n",
    "    return(combination_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD.TransactionDT\n",
      "  feature_type       auc\n",
      "0       counts  0.635902\n",
      "1        means  0.638352\n",
      "2         stds  0.637701\n",
      "3         devs  0.593297\n",
      "4     std_devs  0.384229\n"
     ]
    }
   ],
   "source": [
    "scores = feature_aggregation_eval_2(\n",
    "    categorical_variables = ['ProductCD'],\n",
    "    numerical_variables = ['TransactionDT'],\n",
    "    df = use)\n",
    "\n",
    "for key in scores.keys():\n",
    "    print(key)\n",
    "    print(scores[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations_filter(dict_of_dfs, lower_bound):\n",
    "    scores = dict_of_dfs\n",
    "    combinations = []\n",
    "    for key in scores.keys():\n",
    "\n",
    "        names = key.split('.')\n",
    "        categorical = names[0]\n",
    "        numerical = names[1]\n",
    "\n",
    "        for i in np.arange(0,5):\n",
    "            if scores[key]['auc'].iloc[i] > lower_bound:\n",
    "                method = scores[key]['feature_type'].iloc[i]\n",
    "                combination = [categorical, numerical, method]\n",
    "                combinations.append(combination)\n",
    "\n",
    "    return(combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good idea of what features might be worth creating, I'm going to create a function that appends these new features to our dataframe of explanatory variables. The function will take a tuple and dataframe as input. The tuple contains the numerical variable to be aggregated, the categorical variable to be aggregated across, and the aggregation method. \n",
    "\n",
    "I will do this acros two functions, one that creates the feature itself, and an outer loop that appends each categorical-numerical-method tuple to the full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_creation(categorical, numerical, method, df):\n",
    "    \n",
    "    #Creating some features by default because they will probably be needed anyway\n",
    "    means_temp = df.groupby(categorical)[numerical].agg(['mean']).to_dict()\n",
    "    means = df[categorical].map(means_temp['mean'])\n",
    "    \n",
    "    stds_temp = df.groupby(categorical)[numerical].agg(['std']).to_dict()\n",
    "    stds = df[categorical].map(stds_temp['std'])\n",
    "    \n",
    "    \n",
    "    if method == 'counts':\n",
    "        counts_temp = df[categorical].value_counts().to_dict()\n",
    "        counts = df[categorical].map(counts_temp)\n",
    "        return(counts)\n",
    "    \n",
    "    if method == 'means':\n",
    "        return(means)\n",
    "    \n",
    "    if method == 'stds':\n",
    "        return(stds)\n",
    "    \n",
    "    if method == \"devs\":\n",
    "        devs = df[numerical] - means\n",
    "        return(devs)\n",
    "    \n",
    "    if method == \"std_devs\":\n",
    "        devs = df[numerical] - means\n",
    "        std_devs = devs/stds\n",
    "        return(std_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_aggregation_creation(combination_list, df):\n",
    "    out_df = pd.DataFrame(\n",
    "        {'temp':np.zeros(len(df))}\n",
    "    )\n",
    "    \n",
    "    for i in np.arange(0,len(combination_list)):\n",
    "        combination = combination_list[i]\n",
    "        \n",
    "        print(combination)\n",
    "        feature = feature_creation(\n",
    "            categorical = combination[0],\n",
    "            numerical = combination[1],\n",
    "            method = combination[2],\n",
    "            df=df)\n",
    "        \n",
    "        name = combination[0] + '.' + combination[1] + '.' + combination[2]\n",
    "        out_df[name] = feature\n",
    "        \n",
    "    out_df.drop('temp',axis=1,inplace=True)\n",
    "    return(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_rankings = pd.read_csv('Data/numerics_rankings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_numeric_features = numerics_rankings.iloc[:20]['feature'].tolist()\n",
    "strong_categorical_features = ['M5','P_emaildomain','M4','ProductCD','card6','M6','R_emaildomain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = feature_aggregation_eval_2(\n",
    "    categorical_variables = strong_categorical_features,\n",
    "    numerical_variables = strong_numeric_features,\n",
    "    df = use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = combinations_filter(scores,0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R_emaildomain', 'V108', 'means']\n",
      "['R_emaildomain', 'V108', 'stds']\n",
      "['ProductCD', 'V278', 'stds']\n",
      "['M6', 'V278', 'std_devs']\n",
      "['R_emaildomain', 'V278', 'means']\n",
      "['R_emaildomain', 'V278', 'stds']\n",
      "['R_emaildomain', 'V278', 'devs']\n",
      "['M4', 'V188', 'means']\n",
      "['M6', 'V188', 'means']\n",
      "['M6', 'V188', 'stds']\n",
      "['M6', 'V188', 'devs']\n",
      "['M6', 'V188', 'std_devs']\n",
      "['M4', 'V153', 'stds']\n",
      "['M6', 'V153', 'means']\n",
      "['M6', 'V153', 'stds']\n",
      "['ProductCD', 'V63', 'means']\n",
      "['ProductCD', 'V63', 'stds']\n",
      "['R_emaildomain', 'V63', 'means']\n",
      "['R_emaildomain', 'V63', 'stds']\n",
      "['M4', 'V198', 'means']\n",
      "['M4', 'V198', 'devs']\n",
      "['M4', 'V198', 'std_devs']\n",
      "['ProductCD', 'V198', 'stds']\n",
      "['M6', 'V198', 'means']\n",
      "['ProductCD', 'V129', 'devs']\n",
      "['ProductCD', 'V129', 'std_devs']\n",
      "['M6', 'V129', 'means']\n",
      "['M6', 'V129', 'stds']\n",
      "['M6', 'V129', 'devs']\n",
      "['R_emaildomain', 'V129', 'means']\n",
      "['R_emaildomain', 'V129', 'stds']\n",
      "['R_emaildomain', 'V129', 'devs']\n",
      "['R_emaildomain', 'V129', 'std_devs']\n",
      "['M4', 'V276', 'devs']\n",
      "['ProductCD', 'V276', 'stds']\n",
      "['R_emaildomain', 'V276', 'means']\n",
      "['R_emaildomain', 'V276', 'stds']\n",
      "['R_emaildomain', 'V276', 'devs']\n",
      "['M6', 'V109', 'means']\n",
      "['M6', 'V109', 'devs']\n",
      "['M6', 'V109', 'std_devs']\n",
      "['R_emaildomain', 'V109', 'stds']\n",
      "['M4', 'V58', 'means']\n",
      "['M4', 'V58', 'stds']\n",
      "['ProductCD', 'V58', 'means']\n",
      "['R_emaildomain', 'V58', 'means']\n",
      "['R_emaildomain', 'V58', 'stds']\n",
      "['M6', 'V115', 'means']\n",
      "['M6', 'V115', 'stds']\n",
      "['M6', 'V115', 'devs']\n",
      "['M6', 'V115', 'std_devs']\n",
      "['M5', 'C4', 'std_devs']\n",
      "['M4', 'C4', 'stds']\n",
      "['ProductCD', 'C4', 'means']\n",
      "['ProductCD', 'C4', 'stds']\n",
      "['M6', 'C4', 'std_devs']\n",
      "['R_emaildomain', 'C4', 'means']\n",
      "['R_emaildomain', 'C4', 'stds']\n",
      "['M4', 'C1', 'stds']\n",
      "['M6', 'C1', 'std_devs']\n",
      "['R_emaildomain', 'C1', 'means']\n",
      "['R_emaildomain', 'C1', 'stds']\n",
      "['M4', 'V67', 'stds']\n",
      "['ProductCD', 'V67', 'means']\n",
      "['ProductCD', 'V67', 'stds']\n",
      "['M6', 'V67', 'stds']\n",
      "['R_emaildomain', 'V67', 'means']\n",
      "['R_emaildomain', 'V67', 'stds']\n",
      "['ProductCD', 'C5', 'means']\n",
      "['ProductCD', 'C5', 'stds']\n",
      "['M6', 'C5', 'means']\n",
      "['M6', 'C5', 'stds']\n",
      "['R_emaildomain', 'C5', 'means']\n",
      "['R_emaildomain', 'C5', 'stds']\n",
      "['M4', 'C14', 'stds']\n",
      "['R_emaildomain', 'C14', 'means']\n",
      "['R_emaildomain', 'C14', 'stds']\n"
     ]
    }
   ],
   "source": [
    "new_features = feature_aggregation_creation(combinations,use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_numerical_feats = use[strong_numeric_features]\n",
    "best_categorical_feats = use[strong_categorical_features]\n",
    "best_categorical_feats = best_categorical_feats.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = pd.concat([best_numerical_feats,best_categorical_feats,new_features],axis=1)\n",
    "\n",
    "hybrid = ffill(hybrid)\n",
    "\n",
    "hybrid_train = hybrid.iloc[:100000,:]\n",
    "hybrid_val = hybrid.iloc[100000:200000,:]\n",
    "\n",
    "fraud_train = fraud.iloc[:100000]\n",
    "fraud_val = fraud.iloc[100000:200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've added these new features and encoded the strings, let's give this new data a test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.798216\n",
      "Will train until validation_0-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.812628\n",
      "[2]\tvalidation_0-auc:0.823784\n",
      "[3]\tvalidation_0-auc:0.82734\n",
      "[4]\tvalidation_0-auc:0.82713\n",
      "[5]\tvalidation_0-auc:0.828047\n",
      "[6]\tvalidation_0-auc:0.829488\n",
      "[7]\tvalidation_0-auc:0.833554\n",
      "[8]\tvalidation_0-auc:0.838711\n",
      "[9]\tvalidation_0-auc:0.839557\n",
      "[10]\tvalidation_0-auc:0.840092\n",
      "[11]\tvalidation_0-auc:0.840577\n",
      "[12]\tvalidation_0-auc:0.842423\n",
      "[13]\tvalidation_0-auc:0.842807\n",
      "[14]\tvalidation_0-auc:0.842579\n",
      "[15]\tvalidation_0-auc:0.842959\n",
      "[16]\tvalidation_0-auc:0.841455\n",
      "[17]\tvalidation_0-auc:0.84131\n",
      "[18]\tvalidation_0-auc:0.840495\n",
      "[19]\tvalidation_0-auc:0.83901\n",
      "[20]\tvalidation_0-auc:0.838915\n",
      "[21]\tvalidation_0-auc:0.839463\n",
      "[22]\tvalidation_0-auc:0.83877\n",
      "[23]\tvalidation_0-auc:0.837916\n",
      "[24]\tvalidation_0-auc:0.837335\n",
      "[25]\tvalidation_0-auc:0.836469\n",
      "Stopping. Best iteration:\n",
      "[15]\tvalidation_0-auc:0.842959\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.2,\n",
       "       max_delta_step=0, max_depth=10, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    learning_rate = 0.2,\n",
    "    n_estimators = 100,\n",
    "    max_depth = 10,\n",
    "    objective = 'binary:logistic'\n",
    ") \n",
    "\n",
    "model.fit(hybrid_train, fraud_train, \n",
    "          eval_metric = \"auc\", \n",
    "          eval_set= [(hybrid_val, fraud_val)],\n",
    "          early_stopping_rounds = 10\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've fitted our model, now let's check if the new variables actually contribute amything of significance as opposed to paraphrasing what already exists in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm_hybrid = PermutationImportance(model, random_state=1).fit(hybrid_val.iloc[:100000], fraud_val.iloc[:100000])\n",
    "perm_hybrid_df = eli5.explain_weights_df(perm_hybrid, feature_names = hybrid.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "      <th>standardised_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ProductCD.V129.std_devs</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>67.077305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C14</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>67.049029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M6.C1.std_devs</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>26.124825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M4.V198.devs</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>25.732512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>24.174537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>V58</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>17.592452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ProductCD.V63.means</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>14.966630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R_emaildomain.V108.means</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>14.940358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ProductCD</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>13.495081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R_emaildomain.V129.std_devs</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>12.171865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>card6</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>11.215540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>R_emaildomain.V129.devs</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>9.621405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V188</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>9.433981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>R_emaildomain.V58.means</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>7.750576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P_emaildomain</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>5.828157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C5</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>5.785300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>V163</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5.295136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>R_emaildomain.V276.stds</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>4.956679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V278</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>4.754355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>V333</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>4.733646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>V138</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.458963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>V153</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>4.317563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M4.V188.means</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>3.617042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>M4.V198.std_devs</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>3.601470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>V276</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>3.354102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>V115</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>3.258473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>M5.C4.std_devs</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>3.258473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>M6.V278.std_devs</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>3.241247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>M6.V115.devs</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.857738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>M6.V198.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ProductCD.C4.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>R_emaildomain.C4.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>M4.C1.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>R_emaildomain.C1.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>R_emaildomain.C1.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>M4.V67.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ProductCD.V67.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>M6.V67.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>M6.V115.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>R_emaildomain.V67.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ProductCD.C5.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ProductCD.C5.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>M6.C5.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>M6.C5.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>R_emaildomain.C5.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>R_emaildomain.C5.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>M4.C14.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>M6.V115.std_devs</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>M4.C4.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>M6.V115.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ProductCD.V58.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>M4.V58.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>M4.V58.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>R_emaildomain.C14.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>M6.V109.std_devs</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>M6.V129.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>M6.V129.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ProductCD.V276.stds</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>M6.V109.means</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        feature    weight       std  standardised_weight\n",
       "26      ProductCD.V129.std_devs  0.000070  0.000000                  inf\n",
       "3                            C4  0.002896  0.000043            67.077305\n",
       "0                           C14  0.005882  0.000088            67.049029\n",
       "2                M6.C1.std_devs  0.004056  0.000155            26.124825\n",
       "4                  M4.V198.devs  0.001400  0.000054            25.732512\n",
       "1                            C1  0.004640  0.000192            24.174537\n",
       "7                           V58  0.000662  0.000038            17.592452\n",
       "20          ProductCD.V63.means  0.000112  0.000007            14.966630\n",
       "9      R_emaildomain.V108.means  0.000500  0.000033            14.940358\n",
       "5                     ProductCD  0.000838  0.000062            13.495081\n",
       "8   R_emaildomain.V129.std_devs  0.000632  0.000052            12.171865\n",
       "6                         card6  0.000826  0.000074            11.215540\n",
       "25      R_emaildomain.V129.devs  0.000072  0.000007             9.621405\n",
       "11                         V188  0.000356  0.000038             9.433981\n",
       "28      R_emaildomain.V58.means  0.000058  0.000007             7.750576\n",
       "10                P_emaildomain  0.000382  0.000066             5.828157\n",
       "13                           C5  0.000282  0.000049             5.785300\n",
       "12                         V163  0.000324  0.000061             5.295136\n",
       "16      R_emaildomain.V276.stds  0.000214  0.000043             4.956679\n",
       "19                         V278  0.000118  0.000025             4.754355\n",
       "15                         V333  0.000220  0.000046             4.733646\n",
       "29                         V138  0.000052  0.000012             4.458963\n",
       "17                         V153  0.000188  0.000044             4.317563\n",
       "14                M4.V188.means  0.000226  0.000062             3.617042\n",
       "30             M4.V198.std_devs  0.000042  0.000012             3.601470\n",
       "27                         V276  0.000060  0.000018             3.354102\n",
       "31                         V115  0.000038  0.000012             3.258473\n",
       "32               M5.C4.std_devs  0.000038  0.000012             3.258473\n",
       "24             M6.V278.std_devs  0.000086  0.000027             3.241247\n",
       "41                 M6.V115.devs  0.000014  0.000005             2.857738\n",
       "..                          ...       ...       ...                  ...\n",
       "57                M6.V198.means  0.000000  0.000000                  NaN\n",
       "58            ProductCD.C4.stds  0.000000  0.000000                  NaN\n",
       "59        R_emaildomain.C4.stds  0.000000  0.000000                  NaN\n",
       "60                   M4.C1.stds  0.000000  0.000000                  NaN\n",
       "61       R_emaildomain.C1.means  0.000000  0.000000                  NaN\n",
       "62        R_emaildomain.C1.stds  0.000000  0.000000                  NaN\n",
       "63                  M4.V67.stds  0.000000  0.000000                  NaN\n",
       "64          ProductCD.V67.means  0.000000  0.000000                  NaN\n",
       "65                  M6.V67.stds  0.000000  0.000000                  NaN\n",
       "66                 M6.V115.stds  0.000000  0.000000                  NaN\n",
       "67       R_emaildomain.V67.stds  0.000000  0.000000                  NaN\n",
       "68           ProductCD.C5.means  0.000000  0.000000                  NaN\n",
       "69            ProductCD.C5.stds  0.000000  0.000000                  NaN\n",
       "70                  M6.C5.means  0.000000  0.000000                  NaN\n",
       "71                   M6.C5.stds  0.000000  0.000000                  NaN\n",
       "72       R_emaildomain.C5.means  0.000000  0.000000                  NaN\n",
       "73        R_emaildomain.C5.stds  0.000000  0.000000                  NaN\n",
       "74                  M4.C14.stds  0.000000  0.000000                  NaN\n",
       "75             M6.V115.std_devs  0.000000  0.000000                  NaN\n",
       "76                   M4.C4.stds  0.000000  0.000000                  NaN\n",
       "77                M6.V115.means  0.000000  0.000000                  NaN\n",
       "78          ProductCD.V58.means  0.000000  0.000000                  NaN\n",
       "79                  M4.V58.stds  0.000000  0.000000                  NaN\n",
       "80                 M4.V58.means  0.000000  0.000000                  NaN\n",
       "81      R_emaildomain.C14.means  0.000000  0.000000                  NaN\n",
       "82             M6.V109.std_devs  0.000000  0.000000                  NaN\n",
       "83                M6.V129.means  0.000000  0.000000                  NaN\n",
       "84                 M6.V129.stds  0.000000  0.000000                  NaN\n",
       "85          ProductCD.V276.stds  0.000000  0.000000                  NaN\n",
       "86                M6.V109.means  0.000000  0.000000                  NaN\n",
       "\n",
       "[104 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_hybrid_df['standardised_weight'] = perm_hybrid_df['weight']/perm_hybrid_df['std']\n",
    "perm_hybrid_df = perm_hybrid_df.sort_values('standardised_weight',ascending=False)\n",
    "perm_hybrid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, seems like quite a few of the new features do make a difference. Let's save the rankings as a csv and train up our full model with the signficant ones included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rankings = perm_hybrid_df.to_csv('Data/new_rankings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
