{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will use permutation importance to identify important numeric features to aggregate in the feature-creation notebook. \n",
    "\n",
    "It will also help inform as to whether or not there might be any benefit in dropping any variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import os \n",
    "import time\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv('Data/train_transaction.csv')\n",
    "fraud = train_transaction['isFraud']\n",
    "train_transaction.drop(['isFraud','TransactionID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To get rid of NaNs, we're going to shuffle the data and perform forward filling as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function to deal with NAs by shuffling and forward filling.\n",
    "\n",
    "def ffill(df):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    na_count = df.isna().sum().sum()\n",
    "    while na_count>0:\n",
    "        df = df.sample(frac=1)\n",
    "        df = df.fillna(method='ffill',limit=10)\n",
    "        na_count = df.isna().sum().sum()\n",
    "\n",
    "    \n",
    "    df = df.sort_index()\n",
    "    t1 = time.time()\n",
    "\n",
    "    return(df)\n",
    "    print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = train_transaction.select_dtypes(exclude='object')\n",
    "numerics = ffill(numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118108, 378) (118108, 378)\n"
     ]
    }
   ],
   "source": [
    "numerics_train, numerics_test, fraud_train, fraud_test = train_test_split(numerics, fraud, test_size=0.8)\n",
    "\n",
    "numerics_val, numerics_test, fraud_val, fraud_test = train_test_split(numerics_test, fraud_test, test_size = 0.75)\n",
    "\n",
    "print(numerics_train.shape, numerics_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.816559\n",
      "Will train until validation_0-auc hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-auc:0.84244\n",
      "[2]\tvalidation_0-auc:0.849993\n",
      "[3]\tvalidation_0-auc:0.854918\n",
      "[4]\tvalidation_0-auc:0.860353\n",
      "[5]\tvalidation_0-auc:0.862264\n",
      "[6]\tvalidation_0-auc:0.865374\n",
      "[7]\tvalidation_0-auc:0.868906\n",
      "[8]\tvalidation_0-auc:0.870958\n",
      "[9]\tvalidation_0-auc:0.872244\n",
      "[10]\tvalidation_0-auc:0.876194\n",
      "[11]\tvalidation_0-auc:0.878211\n",
      "[12]\tvalidation_0-auc:0.880306\n",
      "[13]\tvalidation_0-auc:0.882946\n",
      "[14]\tvalidation_0-auc:0.886636\n",
      "[15]\tvalidation_0-auc:0.888655\n",
      "[16]\tvalidation_0-auc:0.891289\n",
      "[17]\tvalidation_0-auc:0.892409\n",
      "[18]\tvalidation_0-auc:0.895087\n",
      "[19]\tvalidation_0-auc:0.895738\n",
      "[20]\tvalidation_0-auc:0.897704\n",
      "[21]\tvalidation_0-auc:0.898366\n",
      "[22]\tvalidation_0-auc:0.900254\n",
      "[23]\tvalidation_0-auc:0.901409\n",
      "[24]\tvalidation_0-auc:0.90231\n",
      "[25]\tvalidation_0-auc:0.902834\n",
      "[26]\tvalidation_0-auc:0.902876\n",
      "[27]\tvalidation_0-auc:0.903888\n",
      "[28]\tvalidation_0-auc:0.904745\n",
      "[29]\tvalidation_0-auc:0.904516\n",
      "[30]\tvalidation_0-auc:0.904956\n",
      "[31]\tvalidation_0-auc:0.905104\n",
      "[32]\tvalidation_0-auc:0.904837\n",
      "[33]\tvalidation_0-auc:0.905053\n",
      "[34]\tvalidation_0-auc:0.904592\n",
      "[35]\tvalidation_0-auc:0.904724\n",
      "[36]\tvalidation_0-auc:0.905207\n",
      "[37]\tvalidation_0-auc:0.905575\n",
      "[38]\tvalidation_0-auc:0.905343\n",
      "[39]\tvalidation_0-auc:0.905648\n",
      "[40]\tvalidation_0-auc:0.906028\n",
      "[41]\tvalidation_0-auc:0.906369\n",
      "[42]\tvalidation_0-auc:0.906357\n",
      "[43]\tvalidation_0-auc:0.906163\n",
      "[44]\tvalidation_0-auc:0.906853\n",
      "[45]\tvalidation_0-auc:0.906891\n",
      "[46]\tvalidation_0-auc:0.906629\n",
      "[47]\tvalidation_0-auc:0.90741\n",
      "[48]\tvalidation_0-auc:0.907696\n",
      "[49]\tvalidation_0-auc:0.90802\n",
      "[50]\tvalidation_0-auc:0.908129\n",
      "[51]\tvalidation_0-auc:0.907922\n",
      "[52]\tvalidation_0-auc:0.90785\n",
      "[53]\tvalidation_0-auc:0.907818\n",
      "[54]\tvalidation_0-auc:0.907847\n",
      "[55]\tvalidation_0-auc:0.907535\n",
      "Stopping. Best iteration:\n",
      "[50]\tvalidation_0-auc:0.908129\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.2,\n",
       "       max_delta_step=0, max_depth=10, min_child_weight=1, missing=None,\n",
       "       n_estimators=300, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    learning_rate = 0.2,\n",
    "    n_estimators = 300,\n",
    "    max_depth = 10,\n",
    "    objective = 'binary:logistic'\n",
    ")\n",
    "\n",
    "eval_set = [(numerics_val, fraud_val)]\n",
    "\n",
    "model.fit(\n",
    "    numerics_train, \n",
    "    fraud_train,\n",
    "    early_stopping_rounds = 5,\n",
    "    eval_set = eval_set,\n",
    "    eval_metric = 'auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "      <th>standardised_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>V163</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>V108</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>V278</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>V188</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>V153</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>V63</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>V198</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>V129</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>V260</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>V333</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>V138</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>V276</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>V109</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>V58</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>V115</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C4</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>52.547597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>46.028264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>V67</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>34.785054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>26.382490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C14</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>25.974625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>V294</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C13</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>21.232756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V317</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>20.932693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C12</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>17.499800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>V54</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>17.104719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C8</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>16.263456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V283</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>15.103495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>C9</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>15.020819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>V308</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>13.745129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C11</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>13.693112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>V157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>V26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>V197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>V11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>V195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>V193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>V22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>V186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>V18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>V185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>V183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>V16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>V173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>V174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>V182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>V14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>V1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>V28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>V194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>V118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>V233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>V122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>V232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>V121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>V120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>V119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>V117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>V32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>V31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>V240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature    weight       std  standardised_weight\n",
       "131    V163  0.000010  0.000000                  inf\n",
       "132    V108  0.000010  0.000000                  inf\n",
       "133    V278  0.000010  0.000000                  inf\n",
       "134    V188  0.000010  0.000000                  inf\n",
       "135    V153  0.000010  0.000000                  inf\n",
       "136     V63  0.000010  0.000000                  inf\n",
       "137    V198  0.000010  0.000000                  inf\n",
       "138    V129  0.000010  0.000000                  inf\n",
       "139    V260  0.000010  0.000000                  inf\n",
       "140    V333  0.000010  0.000000                  inf\n",
       "141    V138  0.000010  0.000000                  inf\n",
       "96     V276  0.000020  0.000000                  inf\n",
       "95     V109  0.000020  0.000000                  inf\n",
       "79      V58  0.000030  0.000000                  inf\n",
       "68     V115  0.000040  0.000000                  inf\n",
       "16       C4  0.000470  0.000009            52.547597\n",
       "0        C1  0.007808  0.000170            46.028264\n",
       "25      V67  0.000220  0.000006            34.785054\n",
       "3        C5  0.002012  0.000076            26.382490\n",
       "1       C14  0.003022  0.000116            25.974625\n",
       "28     V294  0.000196  0.000008            24.500000\n",
       "2       C13  0.002872  0.000135            21.232756\n",
       "6      V317  0.000894  0.000043            20.932693\n",
       "13      C12  0.000512  0.000029            17.499800\n",
       "37      V54  0.000128  0.000007            17.104719\n",
       "23       C8  0.000230  0.000014            16.263456\n",
       "11     V283  0.000622  0.000041            15.103495\n",
       "29       C9  0.000190  0.000013            15.020819\n",
       "24     V308  0.000230  0.000017            13.745129\n",
       "8       C11  0.000752  0.000055            13.693112\n",
       "..      ...       ...       ...                  ...\n",
       "236    V157  0.000000  0.000000                  NaN\n",
       "237     V26  0.000000  0.000000                  NaN\n",
       "238    V197  0.000000  0.000000                  NaN\n",
       "239     V11  0.000000  0.000000                  NaN\n",
       "240    V195  0.000000  0.000000                  NaN\n",
       "241    V193  0.000000  0.000000                  NaN\n",
       "242     V22  0.000000  0.000000                  NaN\n",
       "243    V186  0.000000  0.000000                  NaN\n",
       "244     V18  0.000000  0.000000                  NaN\n",
       "245    V185  0.000000  0.000000                  NaN\n",
       "246    V183  0.000000  0.000000                  NaN\n",
       "247     V16  0.000000  0.000000                  NaN\n",
       "248    V173  0.000000  0.000000                  NaN\n",
       "249    V174  0.000000  0.000000                  NaN\n",
       "250    V182  0.000000  0.000000                  NaN\n",
       "251     V14  0.000000  0.000000                  NaN\n",
       "252      V1  0.000000  0.000000                  NaN\n",
       "253     V28  0.000000  0.000000                  NaN\n",
       "254    V194  0.000000  0.000000                  NaN\n",
       "255    V118  0.000000  0.000000                  NaN\n",
       "258    V233  0.000000  0.000000                  NaN\n",
       "259    V122  0.000000  0.000000                  NaN\n",
       "260    V232  0.000000  0.000000                  NaN\n",
       "261    V121  0.000000  0.000000                  NaN\n",
       "262    V120  0.000000  0.000000                  NaN\n",
       "263    V119  0.000000  0.000000                  NaN\n",
       "265    V117  0.000000  0.000000                  NaN\n",
       "266     V32  0.000000  0.000000                  NaN\n",
       "267     V31  0.000000  0.000000                  NaN\n",
       "268    V240  0.000000  0.000000                  NaN\n",
       "\n",
       "[378 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_numerics = PermutationImportance(model, random_state=1).fit(numerics_val.iloc[:100000,:], fraud_val.iloc[:100000])\n",
    "perm_numerics_df = eli5.explain_weights_df(perm_numerics, feature_names = numerics_val.columns.tolist())\n",
    "perm_numerics_df['standardised_weight'] = perm_numerics_df['weight']/perm_numerics_df['std']\n",
    "perm_numerics_df.sort_values('standardised_weight', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "perm_numerics_df['standardised_weight'] = perm_numerics_df['weight']/perm_numerics_df['std']\n",
    "out_df = perm_numerics_df.sort_values('standardised_weight', ascending=False)\n",
    "out_df.to_csv('Data/numerics_rankings.csv',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
